{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b4c087c-c1aa-4c0c-9716-2b07feba4bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15651339-a3cc-404f-a59d-d72fd9584567",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_url = \"https://fbref.com/en/comps/9/Premier-League-Stats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d90e34f0-b05f-46a4-bfdc-bf75867cecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = requests.get(stats_url)\n",
    "    data.raise_for_status()\n",
    "    \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Error in GET method:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da345420-bc6d-416b-a975-4df46b96f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(data.text)\n",
    "standings_table = soup.select(\"table.stats_table\")[0]\n",
    "standings_table\n",
    "all_anchors = standings_table.find_all(\"a\")\n",
    "team_links = [link for link in [link.get(\"href\") for link in all_anchors] if \"/squads\" in link]\n",
    "final_team_links = [f\"https://fbref.com{l}\" for l in team_links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd1c9781-ca8f-4d66-a1bd-0ae7b20522ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_url = final_team_links[0]\n",
    "data = requests.get(team_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7d1fa90-177e-4110-bcf4-c7123699d26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atato\\AppData\\Local\\Temp\\ipykernel_6212\\2189798775.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "match_stats = pd.read_html(io.StringIO(data.text), match=\"Scores & Fixtures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1634bfee-1c78-4230-86b7-712483fca16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data.text)\n",
    "links = soup.find_all('a')\n",
    "links = [l.get(\"href\") for l in links]\n",
    "links = [l for l in links if l and \"all_comps/shooting\" in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e01919dd-c393-44a6-b3d4-fff2fb729962",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = requests.get(f\"https://fbref.com{links[0]}\")\n",
    "shooting_stats = pd.read_html(io.StringIO(data.text), match=\"Shooting\")[0]\n",
    "shooting_stats.columns = shooting_stats.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b8ab3b8-34c6-4a16-aa62-48e43d908665",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats = match_stats[0].merge(shooting_stats[[\"Date\", \"Sh\", \"SoT\", \"Dist\", \"FK\", \"PK\", \"PKatt\"]], on=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbb292e1-62b8-4376-a704-04a323bb3ed8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(stats_url)\n\u001b[0;32m      7\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(data\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m----> 8\u001b[0m standings_table \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtable.stats_table\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      9\u001b[0m all_anchors \u001b[38;5;241m=\u001b[39m standings_table\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m team_links \u001b[38;5;241m=\u001b[39m [link \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m [link\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m all_anchors] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/squads\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m link]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import io\n",
    "years = list(range(2024, 2018, -1))\n",
    "all_stats = []\n",
    "# stats_url = \"https://fbref.com/en/comps/9/Premier-League-Stats\"\n",
    "for year in years:\n",
    "    data = requests.get(stats_url)\n",
    "    soup = BeautifulSoup(data.text)\n",
    "    standings_table = soup.select('table.stats_table')[0]\n",
    "    all_anchors = standings_table.find_all(\"a\")\n",
    "    team_links = [link for link in [link.get(\"href\") for link in all_anchors] if \"/squads\" in link]\n",
    "    final_team_links = [f\"https://fbref.com{l}\" for l in team_links]\n",
    "\n",
    "    previous_season = soup.select(\"a.prev\")[0].get(\"href\")\n",
    "    stats_url = f\"https://fbref.com{previous_season}\"\n",
    "\n",
    "    for team in final_team_links:\n",
    "        team_name = team.split(\"/\")[-1].replace(\"-Stats\", \"\").replace(\"-\", \" \")\n",
    "        data = requests.get(team)\n",
    "        match_stats = pd.read_html(match=\"Scores & Fixtures\")\n",
    "        \n",
    "        soup = BeautifulSoup(data.text)\n",
    "        links = soup.find_all('a')\n",
    "        links = [l.get(\"href\") for l in links]\n",
    "        links = [l for l in links if l and \"all_comps/shooting\" in l]\n",
    "\n",
    "        data = requests.get(f\"https://fbref.com{links[0]}\")\n",
    "        shooting_stats = pd.read_html(io.StringIO(data.text), match=\"Shooting\")[0]\n",
    "        shooting_stats.columns = shooting_stats.columns.droplevel()\n",
    "\n",
    "        # for unavailable shooting statistics\n",
    "        try: \n",
    "            team_data = match_stats[0].merge(shooting_stats[[\"Date\", \"Sh\", \"SoT\", \"Dist\", \"FK\", \"PK\", \"PKatt\"]], on=\"Date\")\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        team_data = team_data[team_data[\"Comp\"] == \"Premier League\"]\n",
    "        team_data[\"Season\"] = year\n",
    "        team_data[\"Team\"] = team_name\n",
    "        all_stats.append(team_data)\n",
    "        time.sleep(2)    # avoid getting blocked from site\n",
    "    \n",
    "\n",
    "full_match_data = pd.concat(all_stats)\n",
    "full_match_data\n",
    "full_match_data.to_csv(\"matches.csv\")\n",
    "\n",
    "standings_url = \"https://fbref.com/en/comps/9/Premier-League-Stats\"\n",
    "\n",
    "import io\n",
    "import time\n",
    "for year in years:\n",
    "    data = requests.get(standings_url)\n",
    "    soup = BeautifulSoup(data.text)\n",
    "    standings_table = soup.select('table.stats_table')[0]\n",
    "\n",
    "    links = [l.get(\"href\") for l in standings_table.find_all('a')]\n",
    "    links = [l for l in links if '/squads/' in l]\n",
    "    team_urls = [f\"https://fbref.com{l}\" for l in links]\n",
    "    time.sleep(1)  # avoid getting blocked from site\n",
    "    \n",
    "    previous_season = soup.select(\"a.prev\")[0].get(\"href\")\n",
    "    standings_url = f\"https://fbref.com{previous_season}\"\n",
    "    \n",
    "    for team_url in team_urls:\n",
    "        team_name = team_url.split(\"/\")[-1].replace(\"-Stats\", \"\").replace(\"-\", \" \")\n",
    "        data = requests.get(team_url)\n",
    "        matches = pd.read_html(io.StringIO(data.text), match=\"Scores & Fixtures\")[0]\n",
    "        time.sleep(1)  # avoid getting blocked from site\n",
    "        soup = BeautifulSoup(data.text)\n",
    "        links = [l.get(\"href\") for l in soup.find_all('a')]\n",
    "        links = [l for l in links if l and 'all_comps/shooting/' in l]\n",
    "        data = requests.get(f\"https://fbref.com{links[0]}\")\n",
    "        shooting = pd.read_html(io.StringIO(data.text), match=\"Shooting\")[0]\n",
    "        shooting.columns = shooting.columns.droplevel()\n",
    "        # for unavailable shooting statistics\n",
    "        try:\n",
    "            team_data = matches.merge(shooting[[\"Date\", \"Sh\", \"SoT\", \"Dist\", \"FK\", \"PK\", \"PKatt\"]], on=\"Date\")\n",
    "        except ValueError:\n",
    "            continue\n",
    "        team_data = team_data[team_data[\"Comp\"] == \"Premier League\"]\n",
    "        \n",
    "        team_data[\"Season\"] = year\n",
    "        team_data[\"Team\"] = team_name\n",
    "        all_matches.append(team_data)\n",
    "        time.sleep(2)  # avoid getting blocked from site\n",
    "\n",
    "full_match_data = pd.concat(all_matches)\n",
    "full_match_data\n",
    "full_match_data.to_csv(\"matches.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd887c8-b19c-4d32-92d0-b9a429a35708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
